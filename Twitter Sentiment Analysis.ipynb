{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential # to create sequential fit forward neural network\n",
    "from keras.layers import Dense # to create  a dense network\n",
    "import numpy # importing numpy\n",
    "numpy.random.seed(7) #random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = np.loadtxt('train_validation.csv', delimiter = ',', usecols = 1, skiprows = 1, dtype = int) \n",
    "# importing sentiment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Text = np.loadtxt('train_validation.csv', delimiter = ',', usecols = 2, skiprows = 1, dtype = str)\n",
    "# importing sentiment text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['is so sad for my APL friend.............',\n",
       "       'I missed the New Moon trailer...', 'omg its already 7:30 :O', ...,\n",
       "       '@CuPcAkE_2120 ya i thought so',\n",
       "       \"@Cupcake_Dollie Yes. Yes. I'm glad you had more fun with me.\",\n",
       "       '@cupcake_kayla haha yes you do'], dtype='<U255')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Text_Without_Leading_Spaces = np.char.strip(Text) # removing leading spaces\n",
    "Text_Without_Leading_Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sentence = [] # creating empty list\n",
    "for string in Text_Without_Leading_Spaces: #looping over each string \n",
    "        sentence = ''.join(e for e in string if (e.isalnum() or e == ' ')) # removing special characters and joining\n",
    "        sentence_Without_Leading_Spaces = np.char.strip(sentence) # removing leading spaces\n",
    "        final_sentence.append(sentence_Without_Leading_Spaces) # appending to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['is so sad for my APL friend', 'I missed the New Moon trailer',\n",
       "       'omg its already 730 O', ..., 'CuPcAkE2120 ya i thought so',\n",
       "       'CupcakeDollie Yes Yes Im glad you had more fun with me',\n",
       "       'cupcakekayla haha yes you do'], dtype='<U724')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_sentence_array = np.asarray(final_sentence, dtype=np.str) # converting list to numpy array\n",
    "final_sentence_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing test data\n",
    "sentiment_train = sentiment[0:80001] # taking first 80000 entries as training set\n",
    "sentiment_text_train = final_sentence_array[0:80001]\n",
    "sentiment_test = sentiment[80001:] # taking remaining entries as test set\n",
    "sentiment_text_test = final_sentence_array[80001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing and creating instance of CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer # getting count vectorizer \n",
    "vect = CountVectorizer(max_features = 4000) #considering only top 4000 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=4000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learn the vocabulary of the dataset\n",
    "vect.fit(sentiment_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the matrix; this helps us get the features - so now text has been converted to features\n",
    "sentiment_text_train_matrix = vect.transform(sentiment_text_train)\n",
    "sentiment_text_test_matrix = vect.transform(sentiment_text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sentiment_text_train_matrix # Taking X and y for train\n",
    "y_train = sentiment_train\n",
    "X_test = sentiment_text_test_matrix # Taking X and y for test\n",
    "y_test = sentiment_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential # to create sequential fit forward neural network\n",
    "from keras.layers import Dense # to create  a dense network\n",
    "model = Sequential() # creating sequential feed forward neural network\n",
    "model.add(Dense(8, input_dim=4000, activation='relu')) # first layer - rectified linear units\n",
    "model.add(Dense(4, activation='relu')) # second layer - rectified linear units\n",
    "model.add(Dense(1, activation='sigmoid')) # final layer is sigmoid to get single which is probability b/w 0 and 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# binary crossentropy measures the performance of a classification model whose output is a probability value between 0 and 1\n",
    "# adam optimizer is used as it is computationally efficient, and works well with large number of features\n",
    "# measuring the accuracy metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "80001/80001 [==============================] - 6s 79us/step - loss: 0.5741 - acc: 0.7013\n",
      "Epoch 2/5\n",
      "80001/80001 [==============================] - 6s 71us/step - loss: 0.5157 - acc: 0.7467\n",
      "Epoch 3/5\n",
      "80001/80001 [==============================] - 6s 72us/step - loss: 0.5020 - acc: 0.7538\n",
      "Epoch 4/5\n",
      "80001/80001 [==============================] - 6s 72us/step - loss: 0.4909 - acc: 0.7585\n",
      "Epoch 5/5\n",
      "80001/80001 [==============================] - 6s 72us/step - loss: 0.4816 - acc: 0.7631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19f7a9a3e10>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=100)\n",
    "# fitting model on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19999/19999 [==============================] - 1s 47us/step\n",
      "\n",
      "acc: 74.40%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# evaluating performance on teat data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
